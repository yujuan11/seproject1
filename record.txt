---------------------Original script:-------------------------
original_backup.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.381, Time: 2.299171 s
original_backup.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.344, Time: 9.462155 s
original_backup.py: Size: 200, Steps: 50, T*: 0.500: Order: 0.284, Time: 40.509487 s

original_backup.py: Size: 500, Steps: 50, T*: 0.500: Order: 0.265, Time: 334.418559 s

-------------numpy vectorisation-----------
numpy_vec.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.267, Time: 1.782666 s
numpy_vec.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.258, Time: 7.414544 s
numpy_vec.py: Size: 200, Steps: 50, T*: 0.500: Order: 0.257, Time: 29.782095 s



-----------------numba-------------------
setp 1:
 use numba to accelerate one_energy() function, cause this function is called repeatedly which is perfect to use numba.git


LebwohlLasher.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.353, Time: 0.956316 s
LebwohlLasher.py: Size: 50, Steps: 1000, T*: 0.650: Order: 0.620, Time: 26.485633 s

original_backup.py: Size: 50, Steps: 1000, T*: 0.650: Order: 0.542, Time: 68.393555 s

-----------------numba-------------------------------------
setp 2: use numba @njit to MC_step(), get_order(), and all_energy() functions. These functions are called above 50 times, using numba to accelerate is a great method.
There is an error if use @jit to MC_step() function. So use the original MC_step() function. But why can not use @njit to this function?
solve: In MC_step() function, add 'loc=0' for this line 'aran = np.random.normal(loc=0,scale=scale, size=(nmax,nmax))'



ll_numba.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.252, Time: 0.646197 s

-------------------------numba parallel--------------------
step 3: Parallel Numba, numba.prange for loop range in function get_order(), MC_step() and all_energy()
Because there is no loop in one_energy() function, no transformation for parallel execution was possible in this part. Maybe use loop to calculate the energy array then it is possible to use parallel numba in this function.

ll_numba.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.326, Time: 0.648689 s
ll_numba_parallel.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.410, Time: 1.882178 s

WHY IT TAKES MORE TIME AFTER USING PARALLEL NUMBA? TRY BIGGER SIZE:

ll_numba.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.308, Time: 0.799972 s
ll_numba_parallel.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.336, Time: 1.824789 s
ll_numba.py: Size: 200, Steps: 50, T*: 0.500: Order: 0.288, Time: 1.378121 s
ll_numba_parallel.py: Size: 200, Steps: 50, T*: 0.500: Order: 0.253, Time: 2.005059 s

WE CAN SEE THE ADVANTAGE OF PARALLEL WHEN SIZE OVER 300.

ll_numba.py: Size: 300, Steps: 50, T*: 0.500: Order: 0.274, Time: 2.515975 s
ll_numba_parallel.py: Size: 300, Steps: 50, T*: 0.500: Order: 0.299, Time: 2.084997 s
ll_numba.py: Size: 400, Steps: 50, T*: 0.500: Order: 0.257, Time: 3.839702 s
ll_numba_parallel.py: Size: 400, Steps: 50, T*: 0.500: Order: 0.264, Time: 2.264800 s
ll_numba.py: Size: 500, Steps: 50, T*: 0.500: Order: 0.265, Time: 5.646807 s
ll_numba_parallel.py: Size: 500, Steps: 50, T*: 0.500: Order: 0.257, Time: 2.545981 s
ll_numba.py: Size: 1000, Steps: 50, T*: 0.500: Order: 0.258, Time: 23.307858 s
ll_numba_parallel.py: Size: 1000, Steps: 50, T*: 0.500: Order: 0.254, Time: 4.822966 s


------------cython--------------
run_cython.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.330, Time: 2.142927 s
run_cython.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.291, Time: 8.539746 s
run_cython.py: Size: 200, Steps: 50, T*: 0.500: Order: 0.263, Time: 37.078123 s


-------------cython cdef----------------

run_cython.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.313, Time: 2.779956 s
run_cython.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.275, Time: 10.220724 s
run_cython.py: Size: 200, Steps: 50, T*: 0.500: Order: 0.267, Time: 34.133776 s
run_cython.py: Size: 500, Steps: 50, T*: 0.500: Order: 0.258, Time: 239.154359 s

--------cython numpy----------------add three decorator
run_cython.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.328, Time: 2.602348 s
run_cython.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.344, Time: 9.679870 s
run_cython.py: Size: 200, Steps: 50, T*: 0.500: Order: 0.269, Time: 34.386672 s

-----------cython opemMP-----------
run_cython_parallel.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.349, Time: 9.676449 s
run_cython_parallel.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.283, Time: 40.814643 s
run_cython_parallel.py: Size: 200, Steps: 50, T*: 0.500: Order: 0.265, Time: 171.770427 s
run_cython_parallel.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.274, Time: 3.036473 s, threads:1


---------mpi4py-------------------




#################################
--------original----------
original_backup.py: Size: 10, Steps: 50, T*: 0.500: Order: 0.511, Time: 0.104345 s
original_backup.py: Size: 30, Steps: 50, T*: 0.500: Order: 0.281, Time: 0.825113 s
original_backup.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.345, Time: 2.271019 s
original_backup.py: Size: 60, Steps: 50, T*: 0.500: Order: 0.314, Time: 3.432548 s
original_backup.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.278, Time: 9.045514 s
original_backup.py: Size: 300, Steps: 50, T*: 0.500: Order: 0.262, Time: 85.093805 s
original_backup.py: Size: 500, Steps: 50, T*: 0.500: Order: 0.257, Time: 238.323927 s
original_backup.py: Size: 600, Steps: 50, T*: 0.500: Order: 0.259, Time: 337.087822 s
original_backup.py: Size: 1000, Steps: 50, T*: 0.500: Order: 0.258, Time: 964.950696 s

--------------numpy vec----------------------------
numpy_vec.py: Size: 10, Steps: 50, T*: 0.500: Order: 0.295, Time: 0.079776 s
numpy_vec.py: Size: 30, Steps: 50, T*: 0.500: Order: 0.257, Time: 0.651291 s
numpy_vec.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.260, Time: 1.827036 s
numpy_vec.py: Size: 60, Steps: 50, T*: 0.500: Order: 0.269, Time: 2.560840 s
numpy_vec.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.255, Time: 7.168643 s
numpy_vec.py: Size: 300, Steps: 50, T*: 0.500: Order: 0.251, Time: 66.577733 s
numpy_vec.py: Size: 500, Steps: 50, T*: 0.500: Order: 0.251, Time: 189.987961 s
numpy_vec.py: Size: 600, Steps: 50, T*: 0.500: Order: 0.252, Time: 265.748078 s
numpy_vec.py: Size: 1000, Steps: 50, T*: 0.500: Order: 0.250, Time: 930.542168 s

-----------------numba------------------

ll_numba.py: Size: 10, Steps: 50, T*: 0.500: Order: 0.680, Time: 0.478636 s
ll_numba.py: Size: 30, Steps: 50, T*: 0.500: Order: 0.366, Time: 0.431728 s
ll_numba.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.336, Time: 0.489747 s
ll_numba.py: Size: 60, Steps: 50, T*: 0.500: Order: 0.349, Time: 0.469262 s
ll_numba.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.300, Time: 0.559644 s
ll_numba.py: Size: 300, Steps: 50, T*: 0.500: Order: 0.300, Time: 1.780302 s
ll_numba.py: Size: 500, Steps: 50, T*: 0.500: Order: 0.300, Time: 4.120274 s
ll_numba.py: Size: 600, Steps: 50, T*: 0.500: Order: 0.259, Time: 5.980160 s
ll_numba.py: Size: 1000, Steps: 50, T*: 0.500: Order: 0.258, Time: 19.497753 s
ll_numba.py: Size: 3000, Steps: 50, T*: 0.500: Order: 0.251, Time: 219.748886 s
ll_numba.py: Size: 6000, Steps: 50, T*: 0.500: Order: 0.250, Time: 1032.182340 s


----------------numba parallel------------------
ll_numba_parallel.py: Size: 10, Steps: 50, T*: 0.500: Order: 0.898, Time: 1.863352 s
ll_numba_parallel.py: Size: 30, Steps: 50, T*: 0.500: Order: 0.546, Time: 1.919434 s
ll_numba_parallel.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.369, Time: 2.004582 s
ll_numba_parallel.py: Size: 60, Steps: 50, T*: 0.500: Order: 0.268, Time: 1.985747 s
ll_numba_parallel.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.285, Time: 2.075729 s
ll_numba_parallel.py: Size: 300, Steps: 50, T*: 0.500: Order: 0.278, Time: 2.312850 s
ll_numba_parallel.py: Size: 500, Steps: 50, T*: 0.500: Order: 0.264, Time: 2.743273 s
ll_numba_parallel.py: Size: 600, Steps: 50, T*: 0.500: Order: 0.268, Time: 3.086665 s
ll_numba_parallel.py: Size: 1000, Steps: 50, T*: 0.500: Order: 0.257, Time: 5.301149 s
ll_numba_parallel.py: Size: 3000, Steps: 50, T*: 0.500: Order: 0.252, Time: 41.032406 s
ll_numba_parallel.py: Size: 6000, Steps: 50, T*: 0.500: Order: 0.251, Time: 171.318565 s

------------------cython---------------------
run_cython.py: Size: 10, Steps: 50, T*: 0.500: Order: 0.871, Time: 0.176958 s
run_cython.py: Size: 30, Steps: 50, T*: 0.500: Order: 0.599, Time: 1.418982 s
run_cython.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.379, Time: 4.109328 s
run_cython.py: Size: 60, Steps: 50, T*: 0.500: Order: 0.327, Time: 5.709669 s
run_cython.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.273, Time: 14.279910 s
run_cython.py: Size: 300, Steps: 50, T*: 0.500: Order: 0.263, Time: 114.448621 s
run_cython.py: Size: 500, Steps: 50, T*: 0.500: Order: 0.251, Time: 308.576916 s
run_cython.py: Size: 600, Steps: 50, T*: 0.500: Order: 0.256, Time: 442.087894 s
run_cython.py: Size: 1000, Steps: 50, T*: 0.500: Order: 0.257, Time: 1357.741122 s

--------------cython parallel------------
run_cython_parallel.py: Size: 10, Steps: 50, T*: 0.500: Order: 0.602, Time: 0.133127 s, threads:2
run_cython_parallel.py: Size: 30, Steps: 50, T*: 0.500: Order: 0.388, Time: 1.191341 s, threads:2
run_cython_parallel.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.308, Time: 3.479798 s, threads:2
run_cython_parallel.py: Size: 60, Steps: 50, T*: 0.500: Order: 0.296, Time: 5.251970 s, threads:2
run_cython_parallel.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.307, Time: 14.812875 s, threads:2
run_cython_parallel.py: Size: 300, Steps: 50, T*: 0.500: Order: 0.255, Time: 148.859005 s, threads:2
run_cython_parallel.py: Size: 500, Steps: 50, T*: 0.500: Order: 0.258, Time: 467.939478 s, threads:2
run_cython_parallel.py: Size: 600, Steps: 50, T*: 0.500: Order: 0.256, Time: 666.446072 s, threads:2

run_cython_parallel.py: Size: 10, Steps: 50, T*: 0.500: Order: 0.856, Time: 0.313996 s, threads:4
run_cython_parallel.py: Size: 30, Steps: 50, T*: 0.500: Order: 0.348, Time: 3.117776 s, threads:4
run_cython_parallel.py: Size: 50, Steps: 50, T*: 0.500: Order: 0.332, Time: 8.968767 s, threads:4
run_cython_parallel.py: Size: 60, Steps: 50, T*: 0.500: Order: 0.324, Time: 13.378341 s, threads:4
run_cython_parallel.py: Size: 100, Steps: 50, T*: 0.500: Order: 0.320, Time: 41.890315 s, threads:4
run_cython_parallel.py: Size: 300, Steps: 50, T*: 0.500: Order: 0.265, Time: 427.351006 s, threads:4
run_cython_parallel.py: Size: 500, Steps: 50, T*: 0.500: Order: 0.261, Time: 1079.104031 s, threads:4

